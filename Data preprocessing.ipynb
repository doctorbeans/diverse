{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from math import sqrt\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unexpected character found when decoding 'true'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9cb5947747f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_riders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Rider Id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Rider Id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mhexss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'travel_times/540_hexclusters.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mdict_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhexss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tid37/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tid37/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tid37/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tid37/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tid37/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1093\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m             )\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpected character found when decoding 'true'"
     ]
    }
   ],
   "source": [
    "### Pre-dataloading\n",
    "d_types = { \n",
    "             'Platform Type' : np.float16\n",
    "           , 'Placement - Day of Month' : np.uint16\n",
    "           , 'Placement - Weekday (Mo = 1)' : np.uint16\n",
    "           , 'Confirmation - Day of Month' : np.uint16\n",
    "           , 'Confirmation - Weekday (Mo = 1)' : np.uint16\n",
    "           , 'Arrival at Pickup - Day of Month' : np.uint16\n",
    "           , 'Arrival at Pickup - Weekday (Mo = 1)' : np.uint16\n",
    "           , 'Pickup - Day of Month' : np.float16\n",
    "           , 'Pickup - Weekday (Mo = 1)' : np.float16\n",
    "           , 'Arrival at Destination - Day of Month' : np.uint16\n",
    "           , 'Arrival at Destination - Weekday (Mo = 1)' : np.uint16\n",
    "           , 'Distance (KM)' : np.float16\n",
    "           , 'Temperature' : np.float16\n",
    "           , 'Precipitation in millimeters': np.float16\n",
    "           , 'Pickup Lat' : np.float16\n",
    "           , 'Pickup Long' : np.float16\n",
    "           , 'Destination Lat' : np.float16\n",
    "           , 'Destination Long' : np.float16\n",
    "           , 'Time from Pickup to Arrival' : np.uint16\n",
    "           , 'No_Of_Orders' : np.float16\n",
    "           , 'Age' : np.float16\n",
    "           , 'Average_Rating' : np.float16\n",
    "           , 'No_of_Ratings' : np.float16\n",
    "            }\n",
    "\n",
    "d_tpes_rider = {\n",
    "      'No_Of_Orders' : np.uint16      \n",
    "    , 'Age': np.uint16                \n",
    "    , 'Average_Rating': np.float16    \n",
    "    , 'No_of_Ratings': np.uint16      \n",
    "    }\n",
    "\n",
    "df_train = pd.read_csv('Train.csv', dtype=d_types)\n",
    "df_test = pd.read_csv('Test.csv', dtype=d_types)\n",
    "df_riders = pd.read_csv('Riders.csv', dtype=d_tpes_rider)\n",
    "\n",
    "# Join rider info to train/test\n",
    "df_train = pd.merge(df_train, df_riders, how='left', left_on=['Rider Id'], right_on=['Rider Id'])\n",
    "df_test = pd.merge(df_test, df_riders, how='left', left_on=['Rider Id'], right_on=['Rider Id'])\n",
    "\n",
    "hexss = pd.read_json('travel_times/540_hexclusters.json')\n",
    "dict_ = {}\n",
    "for itm in hexss['features']:\n",
    "    dict_[int(itm['properties']['MOVEMENT_ID'])] = Polygon(itm['geometry']['coordinates'][0])\n",
    "\n",
    "\n",
    "## Make pickup and destination points\n",
    "df_train['pickup'] = [Point(row['Pickup Long'], row['Pickup Lat']) for i,row in df_train.iterrows()]\n",
    "df_train['destination'] = [Point(row['Destination Long'], row['Destination Lat']) for i,row in df_train.iterrows()]\n",
    "\n",
    "df_test['pickup'] = [Point(row['Pickup Long'], row['Pickup Lat']) for i,row in df_test.iterrows()]\n",
    "df_test['destination'] = [Point(row['Destination Long'], row['Destination Lat']) for i,row in df_test.iterrows()]\n",
    "\n",
    "## find the hex shape the points belong to\n",
    "df_train['pickup_ID'] = df_train['pickup'].apply(lambda x: max([k if x.within(v) else -1 for k,v in dict_.items()]))\n",
    "df_train['destination_ID'] = df_train['destination'].apply(lambda x: max([k if x.within(v) else -1 for k,v in dict_.items()]))\n",
    "\n",
    "df_test['pickup_ID'] = df_test['pickup'].apply(lambda x: max([k if x.within(v) else -1 for k,v in dict_.items()]))\n",
    "df_test['destination_ID'] = df_test['destination'].apply(lambda x: max([k if x.within(v) else -1 for k,v in dict_.items()]))\n",
    "\n",
    "df_train = df_train.astype({\n",
    "  'pickup_ID': np.int16\n",
    " , 'destination_ID': np.int16   \n",
    "})\n",
    "\n",
    "df_test = df_test.astype({\n",
    "  'pickup_ID': np.int16\n",
    " , 'destination_ID': np.int16   \n",
    "})\n",
    "\n",
    "### Time \n",
    "\n",
    "train_time_col = ['Placement', 'Confirmation', 'Arrival at Pickup', 'Pickup', 'Arrival at Destination']\n",
    "test_time_col  = ['Placement', 'Confirmation', 'Arrival at Pickup', 'Pickup']\n",
    "time_cat = ['Day of Month', 'Weekday (Mo = 1) ', 'Time']\n",
    "\n",
    "for col in test_time_col:\n",
    "    time_col = col + ' - Time'\n",
    "    \n",
    "    df_train[time_col] = pd.to_datetime(df_train[time_col])\n",
    "    df_train[time_col+'_hour'] = df_train[time_col].dt.hour\n",
    "    df_train[time_col] = df_train[time_col].dt.hour * 60 + df_train[time_col].dt.minute\n",
    "    \n",
    "    df_test[time_col] = pd.to_datetime(df_test[time_col])\n",
    "    df_test[time_col+'_hour'] = df_test[time_col].dt.hour\n",
    "    df_test[time_col] = df_test[time_col].dt.hour * 60 + df_test[time_col].dt.minute  \n",
    "    \n",
    "df_train = df_train.astype({\n",
    "      'Placement - Time_hour' : np.int16\n",
    "    , 'Confirmation - Time_hour': np.int16\n",
    "    , 'Arrival at Pickup - Time_hour' : np.int16           \n",
    "    , 'Pickup - Time_hour'   : np.int16\n",
    "    , 'Placement - Time': np.int16\n",
    "    , 'Confirmation - Time' : np.int16\n",
    "    , 'Arrival at Pickup - Time': np.int16\n",
    "    , 'Pickup - Time' : np.int16\n",
    "})\n",
    "\n",
    "df_test = df_test.astype({\n",
    "      'Placement - Time_hour' : np.int16\n",
    "    , 'Confirmation - Time_hour': np.int16\n",
    "    , 'Arrival at Pickup - Time_hour' : np.int16           \n",
    "    , 'Pickup - Time_hour'   : np.int16\n",
    "    , 'Placement - Time': np.int16\n",
    "    , 'Confirmation - Time' : np.int16\n",
    "    , 'Arrival at Pickup - Time': np.int16\n",
    "    , 'Pickup - Time' : np.int16\n",
    "})\n",
    "\n",
    "cat_col = ['Personal or Business']\n",
    "df_train['Personal or Business'] = df_train['Personal or Business'].astype('category').cat.codes\n",
    "df_test['Personal or Business'] = df_test['Personal or Business'].astype('category').cat.codes\n",
    "\n",
    "## Merge the average travel times to the pickup and destination shapes\n",
    "types = {'sourceid' : np.uint16                                   \n",
    "    , 'dstid' : np.uint16                                      \n",
    "    , 'dow' : np.uint16                                       \n",
    "    , 'mean_travel_time' : np.float16                            \n",
    "    , 'standard_deviation_travel_time' : np.float16             \n",
    "    , 'geometric_mean_travel_time'  : np.float16                \n",
    "    , 'geometric_standard_deviation_travel_time': np.float16}\n",
    "tt_weekly = pd.read_csv('travel_times/nairobi-hexclusters-2018-4-WeeklyAggregate.csv', dtype=types)\n",
    "\n",
    "print ('Shape before merge:', df_train.shape)\n",
    "df_train = pd.merge(df_train, tt_weekly\n",
    "              , how='left'\n",
    "              , left_on=['pickup_ID','destination_ID','Pickup - Weekday (Mo = 1)']\n",
    "              , right_on=[ 'dstid','sourceid', 'dow']\n",
    "              , suffixes=('_hour', '_week')\n",
    "         )\n",
    "print ('Shape after merge:', df_train.shape)\n",
    "print ('Shape test before merge:', df_test.shape)\n",
    "df_test = pd.merge(df_test, tt_weekly\n",
    "          , how='left'\n",
    "              , left_on=['pickup_ID','destination_ID','Pickup - Weekday (Mo = 1)']\n",
    "              , right_on=[ 'dstid','sourceid', 'dow']\n",
    "              , suffixes=('_hour', '_week')\n",
    "         )\n",
    "print ('Shape test after merge:', df_test.shape)\n",
    "\n",
    "del tt_weekly\n",
    "\n",
    "df_train.set_index('Order No', inplace=True)\n",
    "df_test.set_index('Order No', inplace=True)\n",
    "\n",
    "## Save Pickle dataframes\n",
    "df_train.to_pickle('df_train.pkl')\n",
    "df_test.to_pickle('df_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
